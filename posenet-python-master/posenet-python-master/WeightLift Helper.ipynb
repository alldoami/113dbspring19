{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\micha\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "3.4.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import cv2\n",
    "print(cv2.__version__)\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import posenet\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for calculating angle between two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle(v1, v2):\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return 180*(np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0)))/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMax(q): #Finds the maximum height\n",
    "\tif q[3] < q[0] and q[3] < q[1] and q[3] < q[2] and q[3] < q[4] and q[3] < q[5] and q[3] < q[6]:\n",
    "\t\treturn q[3]\n",
    "\telse:\n",
    "\t\treturn 0\n",
    "\n",
    "def findMin(q): #Finds the minimum height\n",
    "\tif q[3] > q[0] and q[3] > q[1] and q[3] > q[2] and q[3] > q[4] and q[3] > q[5] and q[3] > q[6]:\n",
    "\t\treturn q[3]\n",
    "\telse:\n",
    "\t\treturn 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareTolerance(list_current, average_prev, tolerance):\n",
    "    print(list_current)\n",
    "    average_current = np.mean(np.asarray(list_current))\n",
    "    difference = np.abs(average_current - average_prev)\n",
    "    if difference < tolerance*average_current:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_input = './exercises'\n",
    "path_output = './output'\n",
    "print_min = True\n",
    "model_number = 101\n",
    "scale_factor = 0.2\n",
    "delay = 3\n",
    "exercise = \"pullup2\"\n",
    "video_format = \".avi\"\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 1\n",
    "font_color = (255,255,255)\n",
    "body_points = {'rightShoulder':None,'rightWrist':None,'rightElbow':None,'leftShoulder':None,'leftWrist':None,'leftElbow':None}\n",
    "body_points_score = {'rightShoulder':None,'rightWrist':None,'rightElbow':None,'leftShoulder':None,'leftWrist':None,'leftElbow':None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filenames = [f.path for f in os.scandir(path_input) if f.is_file() and f.path.endswith(('.png', '.jpg'))]\n",
    "\n",
    "start = time.time()\n",
    "with tf.Session() as sess:\n",
    "    model_cfg, model_outputs = posenet.load_model(model_number, sess)\n",
    "    output_stride = model_cfg['output_stride']\n",
    "    for f in filenames:\n",
    "        print(f)\n",
    "        input_image, draw_image, output_scale = posenet.read_imgfile(\n",
    "            f, scale_factor=scale_factor, output_stride=output_stride)\n",
    "        heatmaps_result, offsets_result, displacement_fwd_result, displacement_bwd_result = sess.run(\n",
    "            model_outputs,\n",
    "            feed_dict={'image:0': input_image}\n",
    "        )\n",
    "\n",
    "        pose_scores, keypoint_scores, keypoint_coords = posenet.decode_multiple_poses(\n",
    "            heatmaps_result.squeeze(axis=0),\n",
    "            offsets_result.squeeze(axis=0),\n",
    "            displacement_fwd_result.squeeze(axis=0),\n",
    "            displacement_bwd_result.squeeze(axis=0),\n",
    "            output_stride=output_stride,\n",
    "            max_pose_detections=10,\n",
    "            min_pose_score=0.25)\n",
    "\n",
    "        keypoint_coords *= output_scale\n",
    "\n",
    "\n",
    "        draw_image = posenet.draw_skel_and_kp(\n",
    "            draw_image, pose_scores, keypoint_scores, keypoint_coords,\n",
    "            min_pose_score=0.25, min_part_score=0.25)\n",
    "\n",
    "        cv2.imwrite(os.path.join(path_output, os.path.relpath(f, path_input)), draw_image)\n",
    "\n",
    "        \n",
    "        print(\"Results for image: %s\" % f)\n",
    "        for pi in range(len(pose_scores)):\n",
    "            if pose_scores[pi] == 0.:\n",
    "                break\n",
    "            print('Pose #%d, score = %f' % (pi, pose_scores[pi]))\n",
    "            for ki, (s, c) in enumerate(zip(keypoint_scores[pi, :], keypoint_coords[pi, :, :])):\n",
    "                #print('Keypoint %s, score = %f, coord = %s' % (posenet.PART_NAMES[ki], s, c))\n",
    "                if posenet.PART_NAMES[ki] in body_points:\n",
    "                    body_points[posenet.PART_NAMES[ki]] = c\n",
    "                    body_points_score[posenet.PART_NAMES[ki]] = s\n",
    "        #Calculate angle between shoulder and wrist using the elbow as the origin\n",
    "        angle_right = angle((body_points['rightShoulder']-body_points['rightElbow']),(body_points['rightWrist']-body_points['rightElbow']))\n",
    "        angle_left = angle((body_points['leftShoulder']-body_points['leftElbow']),(body_points['leftWrist']-body_points['leftElbow']))\n",
    "        \n",
    "        #Calculate the average confidence score of the shoulder, elbow, and wrist\n",
    "        confidence_right = body_points_score['rightShoulder'] + body_points_score['rightElbow'] + body_points_score['rightWrist']\n",
    "        confidence_left = body_points_score['leftShoulder'] + body_points_score['leftElbow'] + body_points_score['leftWrist']\n",
    "        confidence_right /= 3\n",
    "        confidence_left /= 3\n",
    "        \n",
    "        print('Angle Right: %f degrees with confidence %f' %(angle_right,confidence_right))\n",
    "        print('Angle Left: %f degrees with confidence %f' %(angle_left,confidence_left))\n",
    "        print()\n",
    "    print('Average FPS:', len(filenames) / (time.time() - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Analysis for Pushups and Pullups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Desktop\\ML\\113dbspring19\\posenet-python-master\\posenet-python-master\\posenet\\converter\\config.py:9: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  cfg = yaml.load(cfg_f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([1083.3024260285613, 1083.1466722364548, 1083.771948876319, 1082.8170990386566, 1086.3748430524554, 1093.6001349114752, 1092.9917562905844])\n",
      "deque([1127.8644817401837, 1128.560754553064, 1128.2630428958248, 1127.3466511515828, 1131.35926244166, 1131.8763558523995, 1135.1916670365767])\n",
      "deque([1139.612760469511, 1142.0704734108665, 1145.221036044034, 1147.900396966315, 1147.2597037971793, 1142.1630748401988, 1138.7071945388595])\n",
      "Minimum\n",
      "For image number:  1\n",
      "Minimum  Height Found\n",
      "Angle Right: 172.173823 degrees with confidence 0.727902 and average confidence 0.668091\n",
      "Angle Left: 163.371844 degrees with confidence 0.540250 and average confidence 0.632072\n",
      "\n",
      "deque([605.4332505263292, 590.9717066380884, 576.4452138132863, 571.4900825797737, 572.7625514439173, 585.6358063933137, 600.1967408811892])\n",
      "Maximum\n",
      "For image number:  2\n",
      "Maximum  Height Found\n",
      "Angle Right: 31.424997 degrees with confidence 0.935713 and average confidence 0.915604\n",
      "Angle Left: 37.297779 degrees with confidence 0.876540 and average confidence 0.797483\n",
      "\n",
      "deque([1195.541346166041, 1200.6951747745663, 1206.4118814839944, 1209.166873287845, 1207.9452161912793, 1207.7803249606839, 1197.126004764012])\n",
      "Minimum\n",
      "For image number:  3\n",
      "Minimum  Height Found\n",
      "Angle Right: 156.308052 degrees with confidence 0.822098 and average confidence 0.862565\n",
      "Angle Left: 150.352236 degrees with confidence 0.594289 and average confidence 0.608486\n",
      "\n",
      "deque([537.6810049081778, 512.7706782353389, 498.35455282632404, 549.8373924354454, 495.34984083299514, 494.5566766912287, 494.6353335690189])\n",
      "Minimum\n",
      "deque([498.35455282632404, 549.8373924354454, 495.34984083299514, 494.5566766912287, 494.6353335690189, 499.00838084035104, 509.2896054750913])\n",
      "deque([1090.5488225763495, 1086.6676096730419, 1095.6224087801847, 1102.8540665267349, 1101.9317559576652, 1097.9075353052708, 1090.9657798866172])\n",
      "Minimum\n",
      "deque([511.1953243899655, 492.52899645520495, 489.67564847871853, 483.84430526138897, 487.92096660663555, 493.8854643586394, 514.3924386160714])\n",
      "Maximum\n",
      "For image number:  4\n",
      "Maximum  Height Found\n",
      "Angle Right: 36.012865 degrees with confidence 0.862939 and average confidence 0.845056\n",
      "Angle Left: 35.479367 degrees with confidence 0.723273 and average confidence 0.773968\n",
      "\n",
      "deque([1089.9113848797685, 1097.9313176142705, 1098.9746799221286, 1106.8749032949472, 1105.8284008471996, 1101.0291839203278, 1096.564667144379])\n",
      "Minimum\n",
      "For image number:  5\n",
      "Minimum  Height Found\n",
      "Angle Right: 156.165185 degrees with confidence 0.810693 and average confidence 0.826853\n",
      "Angle Left: 158.607708 degrees with confidence 0.642047 and average confidence 0.646631\n",
      "\n",
      "deque([476.15049168970677, 464.3447986949574, 460.5672674798346, 456.88028786399144, 466.4635964926187, 472.8052635688286, 489.56268429446527])\n",
      "Maximum\n",
      "For image number:  6\n",
      "Maximum  Height Found\n",
      "Angle Right: 31.205877 degrees with confidence 0.790705 and average confidence 0.873893\n",
      "Angle Left: 26.892800 degrees with confidence 0.777813 and average confidence 0.831631\n",
      "\n",
      "deque([1077.0053457284903, 1075.3199122044948, 1084.5178420822342, 1085.122889134791, 1080.7125489866578, 1081.8104921811587, 1082.0510808771307])\n",
      "Minimum\n",
      "For image number:  7\n",
      "Minimum  Height Found\n",
      "Angle Right: 173.382167 degrees with confidence 0.828103 and average confidence 0.771531\n",
      "Angle Left: 150.977388 degrees with confidence 0.616044 and average confidence 0.598408\n",
      "\n",
      "deque([493.37216741388494, 475.68542668726536, 464.1833507983715, 455.5206441507711, 456.2645541104403, 466.74909121030333, 476.02305474219384])\n",
      "Maximum\n",
      "For image number:  8\n",
      "Maximum  Height Found\n",
      "Angle Right: 33.840085 degrees with confidence 0.793098 and average confidence 0.849611\n",
      "Angle Left: 24.845452 degrees with confidence 0.889892 and average confidence 0.855079\n",
      "\n",
      "deque([1072.3233484045252, 1065.5322400377943, 1083.0483564897017, 1085.5437653776887, 1084.4738515878653, 1080.0395127333604, 1073.626750202922])\n",
      "Minimum\n",
      "For image number:  9\n",
      "Minimum  Height Found\n",
      "Angle Right: 172.889220 degrees with confidence 0.736204 and average confidence 0.780200\n",
      "Angle Left: 156.745539 degrees with confidence 0.561848 and average confidence 0.605588\n",
      "\n",
      "deque([473.09752724387425, 451.29370196453937, 446.65959504362826, 439.56420581371754, 440.39592792461445, 446.4826010171469, 455.7459970449472])\n",
      "Maximum\n",
      "For image number:  10\n",
      "Maximum  Height Found\n",
      "Angle Right: 23.497790 degrees with confidence 0.757082 and average confidence 0.786941\n",
      "Angle Left: 21.185136 degrees with confidence 0.673493 and average confidence 0.748801\n",
      "\n",
      "deque([1059.1443394252233, 1064.4580625063413, 1084.9476096413352, 1086.517467944653, 1082.8643973214284, 1082.978526722301, 1082.165274483817])\n",
      "Minimum\n",
      "For image number:  11\n",
      "Minimum  Height Found\n",
      "Angle Right: 171.344090 degrees with confidence 0.712548 and average confidence 0.739271\n",
      "Angle Left: 149.916574 degrees with confidence 0.566084 and average confidence 0.597323\n",
      "\n",
      "deque([492.12598964146207, 482.7709656752549, 474.4677913715313, 470.08003829361553, 475.4431210802747, 493.66507076907465, 496.972613049792])\n",
      "Maximum\n",
      "For image number:  12\n",
      "Maximum  Height Found\n",
      "Angle Right: 32.016966 degrees with confidence 0.873772 and average confidence 0.882753\n",
      "Angle Left: 25.692484 degrees with confidence 0.785553 and average confidence 0.788433\n",
      "\n",
      "The maximum angle average is 29.949300 and the standarad deviation is 5.135361\n",
      "The minimum angle average is 161.019485 and the standarad deviation is 8.841335\n",
      "14\n",
      "Average FPS:  0.38349792713536224\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "        model_cfg, model_outputs = posenet.load_model(model_number, sess)\n",
    "        output_stride = model_cfg['output_stride']\n",
    "        cap = cv2.VideoCapture(exercise+video_format)\n",
    "        fourcc = cv2.VideoWriter_fourcc('X','V','I','D')\n",
    "        vid_out = cv2.VideoWriter('output '+exercise+video_format,fourcc, 30, (600,900), True)\n",
    "        cap.set(3, 1080)\n",
    "        cap.set(4, 1920)\n",
    "        #coordinate queue\n",
    "        runningQ = deque()\n",
    "        #create other queues to get more info\n",
    "        moreInfoQ = deque()\n",
    "        imageQ = deque()\n",
    "        infoQ = deque()\n",
    "        start = time.time()\n",
    "        frame_count = 0\n",
    "        picture_count = 1\n",
    "        delay_count = 0\n",
    "        avg_count = 10\n",
    "        avg_counter = 0\n",
    "        threshold = 0\n",
    "        tolerance = 0.2\n",
    "        next_maxima = 'N/A'\n",
    "        maxima_text = 'N/A'\n",
    "        max_count = 0\n",
    "        first = True\n",
    "        # keeps track of prev average\n",
    "        prev_average = 0\n",
    "        init_position = 0\n",
    "        c_r = deque()\n",
    "        c_l = deque()\n",
    "        # maximum angles\n",
    "        st = []\n",
    "        # minimum angles\n",
    "        sb = []\n",
    "        while True:\n",
    "            res, img = cap.read()\n",
    "            if not res:\n",
    "                break\n",
    "            else:\n",
    "                input_image, display_image, output_scale = posenet.process_input(img, scale_factor, output_stride)\n",
    "            info_dict = {\"Body Points\": None, \"Body Points Score\": None, \"Scores Right\": None, \"Scores Left\": None, \"Image\": None}\n",
    "        \n",
    "           \n",
    "            #input_image, display_image, output_scale = posenet.read_cap(\n",
    "              #  cap, scale_factor=0.2, output_stride=output_stride)\n",
    "            \n",
    "            heatmaps_result, offsets_result, displacement_fwd_result, displacement_bwd_result = sess.run(\n",
    "                model_outputs,\n",
    "                feed_dict={'image:0': input_image}\n",
    "            )\n",
    "\n",
    "            pose_scores, keypoint_scores, keypoint_coords = posenet.decode_multi.decode_multiple_poses(\n",
    "                heatmaps_result.squeeze(axis=0),\n",
    "                offsets_result.squeeze(axis=0),\n",
    "                displacement_fwd_result.squeeze(axis=0),\n",
    "                displacement_bwd_result.squeeze(axis=0),\n",
    "                output_stride=output_stride,\n",
    "                max_pose_detections=10,\n",
    "                min_pose_score=0.15)\n",
    "\n",
    "            keypoint_coords *= output_scale\n",
    "\n",
    "            # TODO this isn't particularly fast, use GL for drawing and display someday...\n",
    "            overlay_image = posenet.draw_skel_and_kp(\n",
    "                display_image, pose_scores, keypoint_scores, keypoint_coords,\n",
    "                min_pose_score=0.15, min_part_score=0.1)\n",
    "            \n",
    "            # CHANGE THE RESOLUTION OF THE OUTPUT VIDEO\n",
    "            #overlay_image = cv2.resize(overlay_image, (1920, 1080))\n",
    "            overlay_image = cv2.resize(overlay_image, (600, 900))\n",
    "            \n",
    "            # RESET VARIABLES FOR FOUND MAXIMA\n",
    "            maxima_found = False\n",
    "            \n",
    "            # APPEND THE IMAGE TO THE IMAGEQ\n",
    "            imageQ.append(overlay_image)\n",
    "            for pi in range(len(pose_scores)):\n",
    "                if pose_scores[pi] == 0.:\n",
    "                    break\n",
    "                #logging.warning('Pose #%d, score = %f' % (pi, pose_scores[pi]))\n",
    "                for ki, (s, c) in enumerate(zip(keypoint_scores[pi, :], keypoint_coords[pi, :, :])):\n",
    "                    if posenet.PART_NAMES[ki] == \"leftEye\":\n",
    "                        #print('Keypoint %s, score = %f, coord = %s' % (posenet.PART_NAMES[ki], s, c))\n",
    "                        #adding coordinate to running queue\n",
    "                        runningQ.append(c[0])\n",
    "                        #append more infomation to other queues here\n",
    "                        \n",
    "                        #if length equals 7, then will see if mid point is the min\n",
    "                        if init_position == 0:\n",
    "                            init_position = c[0]\n",
    "                        if len(runningQ) == 7:\n",
    "                            if findMin(runningQ) != 0 and compareTolerance(runningQ,prev_average, tolerance):\n",
    "                                if first == False or (first == True and init_position < c[0]):\n",
    "                                    maxima_found = True\n",
    "                                    maxima_text = 'Minimum'\n",
    "                                    prev_average = np.mean(np.asarray(runningQ))\n",
    "                                    first = False\n",
    "                                    print(maxima_text)\n",
    "                                    \n",
    "                                    max_count += 1\n",
    "                            if findMax(runningQ) != 0 and compareTolerance(runningQ,prev_average, tolerance):\n",
    "                                if first == False or (first == True and init_position > c[0]):\n",
    "                                    maxima_found = True\n",
    "                                    maxima_text = 'Maximum'\n",
    "                                    prev_average = np.mean(np.asarray(runningQ))\n",
    "                                    first = False\n",
    "                                    print(maxima_text)\n",
    "                                    max_count += 1\n",
    "                            runningQ.popleft()\n",
    "                            \n",
    "                            #popleft to all other queues you create for more info here\n",
    "                    if posenet.PART_NAMES[ki] in body_points:\n",
    "                        body_points[posenet.PART_NAMES[ki]] = c\n",
    "                        body_points_score[posenet.PART_NAMES[ki]] = s\n",
    "            \n",
    "                            \n",
    "                        \n",
    "            \n",
    "            #Calculate the average confidence score of the shoulder, elbow, and wrist\n",
    "            confidence_right = body_points_score['rightShoulder'] + body_points_score['rightElbow'] + body_points_score['rightWrist']\n",
    "            confidence_left = body_points_score['leftShoulder'] + body_points_score['leftElbow'] + body_points_score['leftWrist']\n",
    "            confidence_right /= 3\n",
    "            confidence_left /= 3\n",
    "            angle_right = angle((body_points['rightShoulder']-body_points['rightElbow']),(body_points['rightWrist']-body_points['rightElbow']))\n",
    "            angle_left = angle((body_points['leftShoulder']-body_points['leftElbow']),(body_points['leftWrist']-body_points['leftElbow']))\n",
    "                    \n",
    "            # STORE INFORMATION INTO DICTIONARY\n",
    "            info_dict['Body Points'] = body_points\n",
    "            info_dict['Body Points Score'] = body_points_score\n",
    "            info_dict['Scores Right'] = confidence_right\n",
    "            info_dict['Scores Left'] = confidence_left\n",
    "            info_dict['Image'] = overlay_image\n",
    "            \n",
    "            if delay_count < delay:\n",
    "                infoQ.append(info_dict)\n",
    "                delay_count+=1\n",
    "            else:\n",
    "                oldQ = infoQ.popleft()\n",
    "                infoQ.append(info_dict)\n",
    "                \n",
    "            if avg_counter < avg_count:    \n",
    "                c_r.append(confidence_right)\n",
    "                c_l.append(confidence_left)\n",
    "                avg_counter += 1\n",
    "            else:\n",
    "                c_r.popleft()\n",
    "                c_l.popleft()\n",
    "                c_r.append(confidence_right)\n",
    "                c_l.append(confidence_left)\n",
    "            \n",
    "            # MAKE IT SO WE CAN ONLY HAVE ALTERNATING MAXIMUM AND MINIMUM\n",
    "            if next_maxima == 'N/A':\n",
    "                next_maxima = maxima_text\n",
    "            elif maxima_text != next_maxima:\n",
    "                next_maxima = maxima_text\n",
    "            else: \n",
    "                maxima_found = False\n",
    "            \n",
    "            # Create video\n",
    "            data_text = str('Angle Right: %f degrees with confidence %f' %(angle_right,confidence_right))\n",
    "            overlay_image = cv2.putText(overlay_image, data_text, (100,100), font_face, font_scale, font_color)\n",
    "            vid_out.write(overlay_image)\n",
    "            \n",
    "            \n",
    "            if print_min and maxima_found: \n",
    "                avg_r = 0\n",
    "                avg_l = 0\n",
    "                for i in np.arange(avg_count):\n",
    "                    avg_r += c_r[i]\n",
    "                    avg_l += c_l[i]\n",
    "                avg_r /= avg_count\n",
    "                avg_l /= avg_count\n",
    "                if (avg_r > threshold and avg_l > threshold) or (oldQ['Scores Right'] > threshold and oldQ['Scores Left'] > threshold):\n",
    "                    #Calculate angle between shoulder and wrist using the elbow as the origin\n",
    "                    angle_right = angle((oldQ['Body Points']['rightShoulder']-oldQ['Body Points']['rightElbow']),(oldQ['Body Points']['rightWrist']-oldQ['Body Points']['rightElbow']))\n",
    "                    angle_left = angle((oldQ['Body Points']['leftShoulder']-oldQ['Body Points']['leftElbow']),(oldQ['Body Points']['leftWrist']-oldQ['Body Points']['leftElbow']))\n",
    "                    if maxima_text == 'Maximum':\n",
    "                        st.append(angle_right)\n",
    "                        st.append(angle_left)\n",
    "                    else:\n",
    "                        sb.append(angle_right)\n",
    "                        sb.append(angle_left)\n",
    "                    print('For image number: ', picture_count)\n",
    "                    print(maxima_text, ' Height Found')\n",
    "                    print('Angle Right: %f degrees with confidence %f and average confidence %f' %(angle_right,oldQ['Scores Right'],avg_r))\n",
    "                    print('Angle Left: %f degrees with confidence %f and average confidence %f' %(angle_left,oldQ['Scores Left'],avg_l))\n",
    "                    print()\n",
    "                    cv2.imwrite(r'C:\\Users\\micha\\Desktop\\ML\\113dbspring19\\posenet-python-master\\posenet-python-master\\output\\ ' + maxima_text + ' ' + exercise + ' ' +  str(picture_count) + '.jpg',oldQ['Image'])\n",
    "                    \n",
    "                    picture_count += 1\n",
    "            cv2.imshow('posenet', overlay_image)\n",
    "            frame_count += 1\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "        st = np.asarray(st)\n",
    "        sb = np.asarray(sb)\n",
    "        print('The maximum angle average is %f and the standarad deviation is %f'% (np.mean(st),np.std(st)))\n",
    "        print('The minimum angle average is %f and the standarad deviation is %f'% (np.mean(sb),np.std(sb)))\n",
    "        print(max_count)\n",
    "        vid_out.release()\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows();\n",
    "        print('Average FPS: ', frame_count / (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Analysis for Squat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "        model_cfg, model_outputs = posenet.load_model(model_number, sess)\n",
    "        output_stride = model_cfg['output_stride']\n",
    "        cap = cv2.VideoCapture(exercise)\n",
    "        cap.set(3, 1080)\n",
    "        cap.set(4, 1920)\n",
    "        #coordinate queue\n",
    "        runningQ = deque()\n",
    "        #create other queues to get more info\n",
    "        moreInfoQ = deque()\n",
    "        imageQ = deque()\n",
    "        infoQ = deque()\n",
    "        start = time.time()\n",
    "        frame_count = 0\n",
    "        picture_count = 0\n",
    "        delay_count = 0\n",
    "        while True:\n",
    "            res, img = cap.read()\n",
    "            if not res:\n",
    "                break\n",
    "            else:\n",
    "                input_image, display_image, output_scale = posenet.process_input(img, scale_factor, output_stride)\n",
    "            info_dict = {\"Body Points\": None, \"Body Points Score\": None, \"Scores Right\": None, \"Scores Left\": None, \"Image\": None}\n",
    "        \n",
    "           \n",
    "            #input_image, display_image, output_scale = posenet.read_cap(\n",
    "              #  cap, scale_factor=0.2, output_stride=output_stride)\n",
    "            \n",
    "            heatmaps_result, offsets_result, displacement_fwd_result, displacement_bwd_result = sess.run(\n",
    "                model_outputs,\n",
    "                feed_dict={'image:0': input_image}\n",
    "            )\n",
    "\n",
    "            pose_scores, keypoint_scores, keypoint_coords = posenet.decode_multi.decode_multiple_poses(\n",
    "                heatmaps_result.squeeze(axis=0),\n",
    "                offsets_result.squeeze(axis=0),\n",
    "                displacement_fwd_result.squeeze(axis=0),\n",
    "                displacement_bwd_result.squeeze(axis=0),\n",
    "                output_stride=output_stride,\n",
    "                max_pose_detections=10,\n",
    "                min_pose_score=0.15)\n",
    "\n",
    "            keypoint_coords *= output_scale\n",
    "\n",
    "            # TODO this isn't particularly fast, use GL for drawing and display someday...\n",
    "            overlay_image = posenet.draw_skel_and_kp(\n",
    "                display_image, pose_scores, keypoint_scores, keypoint_coords,\n",
    "                min_pose_score=0.15, min_part_score=0.1)\n",
    "            \n",
    "            #overlay_image = cv2.resize(overlay_image, (1024, 960))\n",
    "            overlay_image = cv2.resize(overlay_image, (600, 900))\n",
    "            minimum_found = False\n",
    "\n",
    "            imageQ.append(overlay_image)\n",
    "            for pi in range(len(pose_scores)):\n",
    "                if pose_scores[pi] == 0.:\n",
    "                    break\n",
    "                #logging.warning('Pose #%d, score = %f' % (pi, pose_scores[pi]))\n",
    "                for ki, (s, c) in enumerate(zip(keypoint_scores[pi, :], keypoint_coords[pi, :, :])):\n",
    "                    if posenet.PART_NAMES[ki] == \"leftEye\":\n",
    "                        #print('Keypoint %s, score = %f, coord = %s' % (posenet.PART_NAMES[ki], s, c))\n",
    "                        #adding coordinate to running queue\n",
    "                        runningQ.append(c[0])\n",
    "                        #append more infomation to other queues here\n",
    "                        \n",
    "                        #if length equals 7, then will see if mid point is the min\n",
    "                        if len(runningQ) == 7:\n",
    "                            if findMin(runningQ) != 0:\n",
    "                                #print('FOUND MIN')\n",
    "                                minimum_found = True\n",
    "                                #print(findMin(runningQ))\n",
    "                            runningQ.popleft()\n",
    "                            #popleft to all other queues you create for more info here\n",
    "                    if posenet.PART_NAMES[ki] in body_points:\n",
    "                        body_points[posenet.PART_NAMES[ki]] = c\n",
    "                        body_points_score[posenet.PART_NAMES[ki]] = s\n",
    "                        \n",
    "                            \n",
    "                        \n",
    "            info_dict['Body Points'] = body_points\n",
    "            info_dict['Body Points Score'] = body_points_score\n",
    "            \n",
    "            #Calculate the average confidence score of the shoulder, elbow, and wrist\n",
    "            confidence_right = body_points_score['rightShoulder'] + body_points_score['rightElbow'] + body_points_score['rightWrist']\n",
    "            confidence_left = body_points_score['leftShoulder'] + body_points_score['leftElbow'] + body_points_score['leftWrist']\n",
    "            confidence_right /= 3\n",
    "            confidence_left /= 3\n",
    "            info_dict['Scores Right'] = confidence_right\n",
    "            info_dict['Scores Left'] = confidence_left\n",
    "            info_dict['Image'] = overlay_image\n",
    "            \n",
    "            if delay_count < delay:\n",
    "                infoQ.append(info_dict)\n",
    "                delay_count+=1\n",
    "            else:\n",
    "                oldQ = infoQ.popleft()\n",
    "                infoQ.append(info_dict)\n",
    "                \n",
    "            if print_min and minimum_found:\n",
    "                for i in np.arange(3):\n",
    "                    avg_r += infoQ[i]['']\n",
    "                #Calculate angle between shoulder and wrist using the elbow as the origin\n",
    "                angle_right = angle((oldQ['Body Points']['rightShoulder']-oldQ['Body Points']['rightElbow']),(oldQ['Body Points']['rightWrist']-oldQ['Body Points']['rightElbow']))\n",
    "                angle_left = angle((oldQ['Body Points']['leftShoulder']-oldQ['Body Points']['leftElbow']),(oldQ['Body Points']['leftWrist']-oldQ['Body Points']['leftElbow']))\n",
    "                print('Maximum Height Found')\n",
    "                print('Angle Right: %f degrees with confidence %f' %(angle_right,confidence_right))\n",
    "                print('Angle Left: %f degrees with confidence %f' %(angle_left,confidence_left))\n",
    "                print()\n",
    "                cv2.imwrite(r'C:\\Users\\micha\\Desktop\\ML\\113dbspring19\\posenet-python-master\\posenet-python-master\\output\\maximum_squat' + exercise + str(picture_count) + '.jpg',oldQ['Image'])\n",
    "\n",
    "                picture_count += 1\n",
    "            cv2.imshow('posenet', overlay_image)\n",
    "            frame_count += 1\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows();\n",
    "        print('Average FPS: ', frame_count / (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_r = 0\n",
    "for i in np.arange(4):\n",
    "    print(infoQ[i]['Scores Right'])\n",
    "    avg_r += infoQ[i]['Scores Right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
