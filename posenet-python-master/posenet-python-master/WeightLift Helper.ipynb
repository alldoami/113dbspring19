{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\micha\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "3.4.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import cv2\n",
    "print(cv2.__version__)\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import posenet\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for calculating angle between two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle(v1, v2):\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return 180*(np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0)))/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMax(q): #Finds the maximum height\n",
    "\tif q[3] < q[0] and q[3] < q[1] and q[3] < q[2] and q[3] < q[4] and q[3] < q[5] and q[3] < q[6]:\n",
    "\t\treturn q[3]\n",
    "\telse:\n",
    "\t\treturn 0\n",
    "\n",
    "def findMin(q): #Finds the minimum height\n",
    "\tif q[3] > q[0] and q[3] > q[1] and q[3] > q[2] and q[3] > q[4] and q[3] > q[5] and q[3] > q[6]:\n",
    "\t\treturn q[3]\n",
    "\telse:\n",
    "\t\treturn 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareTolerance(list_current, average_prev, tolerance):\n",
    "    print(list_current)\n",
    "    average_current = np.mean(np.asarray(list_current))\n",
    "    difference = np.abs(average_current - average_prev)\n",
    "    if difference < tolerance*average_current:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_input = './exercises'\n",
    "path_output = './output'\n",
    "print_min = True\n",
    "model_number = 101\n",
    "scale_factor = 0.2\n",
    "delay = 3\n",
    "exercise = \"pullup\"\n",
    "video_format = \".avi\"\n",
    "body_points = {'rightShoulder':None,'rightWrist':None,'rightElbow':None,'leftShoulder':None,'leftWrist':None,'leftElbow':None}\n",
    "body_points_score = {'rightShoulder':None,'rightWrist':None,'rightElbow':None,'leftShoulder':None,'leftWrist':None,'leftElbow':None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filenames = [f.path for f in os.scandir(path_input) if f.is_file() and f.path.endswith(('.png', '.jpg'))]\n",
    "\n",
    "start = time.time()\n",
    "with tf.Session() as sess:\n",
    "    model_cfg, model_outputs = posenet.load_model(model_number, sess)\n",
    "    output_stride = model_cfg['output_stride']\n",
    "    for f in filenames:\n",
    "        print(f)\n",
    "        input_image, draw_image, output_scale = posenet.read_imgfile(\n",
    "            f, scale_factor=scale_factor, output_stride=output_stride)\n",
    "        heatmaps_result, offsets_result, displacement_fwd_result, displacement_bwd_result = sess.run(\n",
    "            model_outputs,\n",
    "            feed_dict={'image:0': input_image}\n",
    "        )\n",
    "\n",
    "        pose_scores, keypoint_scores, keypoint_coords = posenet.decode_multiple_poses(\n",
    "            heatmaps_result.squeeze(axis=0),\n",
    "            offsets_result.squeeze(axis=0),\n",
    "            displacement_fwd_result.squeeze(axis=0),\n",
    "            displacement_bwd_result.squeeze(axis=0),\n",
    "            output_stride=output_stride,\n",
    "            max_pose_detections=10,\n",
    "            min_pose_score=0.25)\n",
    "\n",
    "        keypoint_coords *= output_scale\n",
    "\n",
    "\n",
    "        draw_image = posenet.draw_skel_and_kp(\n",
    "            draw_image, pose_scores, keypoint_scores, keypoint_coords,\n",
    "            min_pose_score=0.25, min_part_score=0.25)\n",
    "\n",
    "        cv2.imwrite(os.path.join(path_output, os.path.relpath(f, path_input)), draw_image)\n",
    "\n",
    "        \n",
    "        print(\"Results for image: %s\" % f)\n",
    "        for pi in range(len(pose_scores)):\n",
    "            if pose_scores[pi] == 0.:\n",
    "                break\n",
    "            print('Pose #%d, score = %f' % (pi, pose_scores[pi]))\n",
    "            for ki, (s, c) in enumerate(zip(keypoint_scores[pi, :], keypoint_coords[pi, :, :])):\n",
    "                #print('Keypoint %s, score = %f, coord = %s' % (posenet.PART_NAMES[ki], s, c))\n",
    "                if posenet.PART_NAMES[ki] in body_points:\n",
    "                    body_points[posenet.PART_NAMES[ki]] = c\n",
    "                    body_points_score[posenet.PART_NAMES[ki]] = s\n",
    "        #Calculate angle between shoulder and wrist using the elbow as the origin\n",
    "        angle_right = angle((body_points['rightShoulder']-body_points['rightElbow']),(body_points['rightWrist']-body_points['rightElbow']))\n",
    "        angle_left = angle((body_points['leftShoulder']-body_points['leftElbow']),(body_points['leftWrist']-body_points['leftElbow']))\n",
    "        \n",
    "        #Calculate the average confidence score of the shoulder, elbow, and wrist\n",
    "        confidence_right = body_points_score['rightShoulder'] + body_points_score['rightElbow'] + body_points_score['rightWrist']\n",
    "        confidence_left = body_points_score['leftShoulder'] + body_points_score['leftElbow'] + body_points_score['leftWrist']\n",
    "        confidence_right /= 3\n",
    "        confidence_left /= 3\n",
    "        \n",
    "        print('Angle Right: %f degrees with confidence %f' %(angle_right,confidence_right))\n",
    "        print('Angle Left: %f degrees with confidence %f' %(angle_left,confidence_left))\n",
    "        print()\n",
    "    print('Average FPS:', len(filenames) / (time.time() - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Analysis for Pushups and Pullups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Desktop\\ML\\113dbspring19\\posenet-python-master\\posenet-python-master\\posenet\\converter\\config.py:9: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  cfg = yaml.load(cfg_f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([644.8326986733969, 646.3440601299335, 628.0666725852273, 649.0497305733817, 594.835693359375, 583.152689351664, 569.6527000526329])\n",
      "Minimum\n",
      "For image number:  1\n",
      "Minimum  Height Found\n",
      "Angle Right: 29.237284 degrees with confidence 0.801933 and average confidence 0.742384\n",
      "Angle Left: 17.318747 degrees with confidence 0.486199 and average confidence 0.726782\n",
      "\n",
      "deque([569.6527000526329, 551.8843474945464, 542.513201032366, 528.4716535295759, 530.6528605671672, 535.208022873123, 530.8018727488331])\n",
      "deque([1030.074411169275, 1034.6386529501383, 1029.4382011116325, 1037.0572304787574, 1031.4040059671772, 1035.2539855659782, 1024.0276425844663])\n",
      "Minimum\n",
      "deque([508.92428628500403, 490.92125434380074, 480.7592423674348, 469.4539454076197, 475.08926411418173, 474.3375855483018, 490.0265201717228])\n",
      "Maximum\n",
      "For image number:  2\n",
      "Maximum  Height Found\n",
      "Angle Right: 36.875980 degrees with confidence 0.953636 and average confidence 0.807884\n",
      "Angle Left: 26.781336 degrees with confidence 0.945012 and average confidence 0.733482\n",
      "\n",
      "deque([1120.8852482585164, 1120.8380088310737, 1123.4702067189403, 1126.3350035432097, 1124.112436666117, 1116.9993540900093, 1116.0938330811339])\n",
      "Minimum\n",
      "For image number:  3\n",
      "Minimum  Height Found\n",
      "Angle Right: 153.295383 degrees with confidence 0.725553 and average confidence 0.664537\n",
      "Angle Left: 154.897159 degrees with confidence 0.657509 and average confidence 0.715082\n",
      "\n",
      "deque([523.435287673752, 517.5990220107042, 506.6564798726664, 503.38793786779627, 504.006898557985, 514.8146489130986, 529.4784815404322])\n",
      "Maximum\n",
      "For image number:  4\n",
      "Maximum  Height Found\n",
      "Angle Right: 36.733496 degrees with confidence 0.963715 and average confidence 0.906551\n",
      "Angle Left: 22.363404 degrees with confidence 0.712001 and average confidence 0.717118\n",
      "\n",
      "deque([1061.4771839488635, 1064.6655923422281, 1069.1775988293932, 1072.6510715236911, 1069.6116895799512, 1072.5480687525364, 1070.4463461343344])\n",
      "Minimum\n",
      "For image number:  5\n",
      "Minimum  Height Found\n",
      "Angle Right: 155.573328 degrees with confidence 0.667239 and average confidence 0.702543\n",
      "Angle Left: 161.239093 degrees with confidence 0.781506 and average confidence 0.783077\n",
      "\n",
      "deque([1070.4463461343344, 1084.4616524832588, 1083.151421088677, 1086.97643725903, 1084.7051542207791, 1067.219618760146, 1068.7080569576908])\n",
      "deque([452.79247016411324, 432.7202893542005, 421.02644645393667, 414.8672564617999, 415.5768472250406, 417.1960595861658, 424.4492369812804])\n",
      "Maximum\n",
      "For image number:  6\n",
      "Maximum  Height Found\n",
      "Angle Right: 23.606785 degrees with confidence 0.926234 and average confidence 0.869459\n",
      "Angle Left: 26.628379 degrees with confidence 0.654045 and average confidence 0.730797\n",
      "\n",
      "The maximum angle average is 28.831563 and the standarad deviation is 5.850157\n",
      "The minimum angle average is 111.926833 and the standarad deviation is 62.826179\n",
      "7\n",
      "Average FPS:  9.755230741296824\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "        model_cfg, model_outputs = posenet.load_model(model_number, sess)\n",
    "        output_stride = model_cfg['output_stride']\n",
    "        cap = cv2.VideoCapture(exercise+video_format)\n",
    "        cap.set(3, 1080)\n",
    "        cap.set(4, 1920)\n",
    "        #coordinate queue\n",
    "        runningQ = deque()\n",
    "        #create other queues to get more info\n",
    "        moreInfoQ = deque()\n",
    "        imageQ = deque()\n",
    "        infoQ = deque()\n",
    "        start = time.time()\n",
    "        frame_count = 0\n",
    "        picture_count = 1\n",
    "        delay_count = 0\n",
    "        avg_count = 10\n",
    "        avg_counter = 0\n",
    "        threshold = 0\n",
    "        tolerance = 0.2\n",
    "        next_maxima = 'N/A'\n",
    "        maxima_text = 'N/A'\n",
    "        max_count = 0\n",
    "        # keeps track of prev average\n",
    "        prev_average = 0\n",
    "        init_position = 0\n",
    "        c_r = deque()\n",
    "        c_l = deque()\n",
    "        # maximum angles\n",
    "        st = []\n",
    "        # minimum angles\n",
    "        sb = []\n",
    "        while True:\n",
    "            res, img = cap.read()\n",
    "            if not res:\n",
    "                break\n",
    "            else:\n",
    "                input_image, display_image, output_scale = posenet.process_input(img, scale_factor, output_stride)\n",
    "            info_dict = {\"Body Points\": None, \"Body Points Score\": None, \"Scores Right\": None, \"Scores Left\": None, \"Image\": None}\n",
    "        \n",
    "           \n",
    "            #input_image, display_image, output_scale = posenet.read_cap(\n",
    "              #  cap, scale_factor=0.2, output_stride=output_stride)\n",
    "            \n",
    "            heatmaps_result, offsets_result, displacement_fwd_result, displacement_bwd_result = sess.run(\n",
    "                model_outputs,\n",
    "                feed_dict={'image:0': input_image}\n",
    "            )\n",
    "\n",
    "            pose_scores, keypoint_scores, keypoint_coords = posenet.decode_multi.decode_multiple_poses(\n",
    "                heatmaps_result.squeeze(axis=0),\n",
    "                offsets_result.squeeze(axis=0),\n",
    "                displacement_fwd_result.squeeze(axis=0),\n",
    "                displacement_bwd_result.squeeze(axis=0),\n",
    "                output_stride=output_stride,\n",
    "                max_pose_detections=10,\n",
    "                min_pose_score=0.15)\n",
    "\n",
    "            keypoint_coords *= output_scale\n",
    "\n",
    "            # TODO this isn't particularly fast, use GL for drawing and display someday...\n",
    "            overlay_image = posenet.draw_skel_and_kp(\n",
    "                display_image, pose_scores, keypoint_scores, keypoint_coords,\n",
    "                min_pose_score=0.15, min_part_score=0.1)\n",
    "            \n",
    "            # CHANGE THE RESOLUTION OF THE OUTPUT VIDEO\n",
    "            #overlay_image = cv2.resize(overlay_image, (1920, 1080))\n",
    "            overlay_image = cv2.resize(overlay_image, (600, 900))\n",
    "            \n",
    "            # RESET VARIABLES FOR FOUND MAXIMA\n",
    "            maxima_found = False\n",
    "            \n",
    "            # APPEND THE IMAGE TO THE IMAGEQ\n",
    "            imageQ.append(overlay_image)\n",
    "            for pi in range(len(pose_scores)):\n",
    "                if pose_scores[pi] == 0.:\n",
    "                    break\n",
    "                #logging.warning('Pose #%d, score = %f' % (pi, pose_scores[pi]))\n",
    "                for ki, (s, c) in enumerate(zip(keypoint_scores[pi, :], keypoint_coords[pi, :, :])):\n",
    "                    if posenet.PART_NAMES[ki] == \"leftEye\":\n",
    "                        #print('Keypoint %s, score = %f, coord = %s' % (posenet.PART_NAMES[ki], s, c))\n",
    "                        #adding coordinate to running queue\n",
    "                        runningQ.append(c[0])\n",
    "                        #append more infomation to other queues here\n",
    "                        \n",
    "                        #if length equals 7, then will see if mid point is the min\n",
    "                        if init_position == 0:\n",
    "                            init_position = c[0]\n",
    "                        if len(runningQ) == 7:\n",
    "                            if findMin(runningQ) != 0 and compareTolerance(runningQ,prev_average, tolerance):\n",
    "                                maxima_found = True\n",
    "                                maxima_text = 'Minimum'\n",
    "                                prev_average = np.mean(np.asarray(runningQ))\n",
    "                                print(maxima_text)\n",
    "                                max_count += 1\n",
    "                            if findMax(runningQ) != 0 and compareTolerance(runningQ,prev_average, tolerance):\n",
    "                                maxima_found = True\n",
    "                                maxima_text = 'Maximum'\n",
    "                                prev_average = np.mean(np.asarray(runningQ))\n",
    "                                print(maxima_text)\n",
    "                                max_count += 1\n",
    "                            runningQ.popleft()\n",
    "                            \n",
    "                            #popleft to all other queues you create for more info here\n",
    "                    if posenet.PART_NAMES[ki] in body_points:\n",
    "                        body_points[posenet.PART_NAMES[ki]] = c\n",
    "                        body_points_score[posenet.PART_NAMES[ki]] = s\n",
    "            \n",
    "                            \n",
    "                        \n",
    "            \n",
    "            #Calculate the average confidence score of the shoulder, elbow, and wrist\n",
    "            confidence_right = body_points_score['rightShoulder'] + body_points_score['rightElbow'] + body_points_score['rightWrist']\n",
    "            confidence_left = body_points_score['leftShoulder'] + body_points_score['leftElbow'] + body_points_score['leftWrist']\n",
    "            confidence_right /= 3\n",
    "            confidence_left /= 3\n",
    "            \n",
    "            # STORE INFORMATION INTO DICTIONARY\n",
    "            info_dict['Body Points'] = body_points\n",
    "            info_dict['Body Points Score'] = body_points_score\n",
    "            info_dict['Scores Right'] = confidence_right\n",
    "            info_dict['Scores Left'] = confidence_left\n",
    "            info_dict['Image'] = overlay_image\n",
    "            \n",
    "            if delay_count < delay:\n",
    "                infoQ.append(info_dict)\n",
    "                delay_count+=1\n",
    "            else:\n",
    "                oldQ = infoQ.popleft()\n",
    "                infoQ.append(info_dict)\n",
    "                \n",
    "            if avg_counter < avg_count:    \n",
    "                c_r.append(confidence_right)\n",
    "                c_l.append(confidence_left)\n",
    "                avg_counter += 1\n",
    "            else:\n",
    "                c_r.popleft()\n",
    "                c_l.popleft()\n",
    "                c_r.append(confidence_right)\n",
    "                c_l.append(confidence_left)\n",
    "            \n",
    "            # MAKE IT SO WE CAN ONLY HAVE ALTERNATING MAXIMUM AND MINIMUM\n",
    "            if next_maxima == 'N/A':\n",
    "                next_maxima = maxima_text\n",
    "            elif maxima_text != next_maxima:\n",
    "                next_maxima = maxima_text\n",
    "            else: \n",
    "                maxima_found = False\n",
    "            \n",
    "            \n",
    "            if print_min and maxima_found: \n",
    "                avg_r = 0\n",
    "                avg_l = 0\n",
    "                for i in np.arange(avg_count):\n",
    "                    avg_r += c_r[i]\n",
    "                    avg_l += c_l[i]\n",
    "                avg_r /= avg_count\n",
    "                avg_l /= avg_count\n",
    "                if (avg_r > threshold and avg_l > threshold) or (oldQ['Scores Right'] > threshold and oldQ['Scores Left'] > threshold):\n",
    "                    #Calculate angle between shoulder and wrist using the elbow as the origin\n",
    "                    angle_right = angle((oldQ['Body Points']['rightShoulder']-oldQ['Body Points']['rightElbow']),(oldQ['Body Points']['rightWrist']-oldQ['Body Points']['rightElbow']))\n",
    "                    angle_left = angle((oldQ['Body Points']['leftShoulder']-oldQ['Body Points']['leftElbow']),(oldQ['Body Points']['leftWrist']-oldQ['Body Points']['leftElbow']))\n",
    "                    if maxima_text == 'Maximum':\n",
    "                        st.append(angle_right)\n",
    "                        st.append(angle_left)\n",
    "                    else:\n",
    "                        sb.append(angle_right)\n",
    "                        sb.append(angle_left)\n",
    "                    print('For image number: ', picture_count)\n",
    "                    print(maxima_text, ' Height Found')\n",
    "                    print('Angle Right: %f degrees with confidence %f and average confidence %f' %(angle_right,oldQ['Scores Right'],avg_r))\n",
    "                    print('Angle Left: %f degrees with confidence %f and average confidence %f' %(angle_left,oldQ['Scores Left'],avg_l))\n",
    "                    print()\n",
    "                    cv2.imwrite(r'C:\\Users\\micha\\Desktop\\ML\\113dbspring19\\posenet-python-master\\posenet-python-master\\output\\ ' + maxima_text + ' ' + exercise + ' ' +  str(picture_count) + '.jpg',oldQ['Image'])\n",
    "                    \n",
    "                    picture_count += 1\n",
    "            cv2.imshow('posenet', overlay_image)\n",
    "            frame_count += 1\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "        st = np.asarray(st)\n",
    "        sb = np.asarray(sb)\n",
    "        print('The maximum angle average is %f and the standarad deviation is %f'% (np.mean(st),np.std(st)))\n",
    "        print('The minimum angle average is %f and the standarad deviation is %f'% (np.mean(sb),np.std(sb)))\n",
    "        print(max_count)\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows();\n",
    "        print('Average FPS: ', frame_count / (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Analysis for Squat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "        model_cfg, model_outputs = posenet.load_model(model_number, sess)\n",
    "        output_stride = model_cfg['output_stride']\n",
    "        cap = cv2.VideoCapture(exercise)\n",
    "        cap.set(3, 1080)\n",
    "        cap.set(4, 1920)\n",
    "        #coordinate queue\n",
    "        runningQ = deque()\n",
    "        #create other queues to get more info\n",
    "        moreInfoQ = deque()\n",
    "        imageQ = deque()\n",
    "        infoQ = deque()\n",
    "        start = time.time()\n",
    "        frame_count = 0\n",
    "        picture_count = 0\n",
    "        delay_count = 0\n",
    "        while True:\n",
    "            res, img = cap.read()\n",
    "            if not res:\n",
    "                break\n",
    "            else:\n",
    "                input_image, display_image, output_scale = posenet.process_input(img, scale_factor, output_stride)\n",
    "            info_dict = {\"Body Points\": None, \"Body Points Score\": None, \"Scores Right\": None, \"Scores Left\": None, \"Image\": None}\n",
    "        \n",
    "           \n",
    "            #input_image, display_image, output_scale = posenet.read_cap(\n",
    "              #  cap, scale_factor=0.2, output_stride=output_stride)\n",
    "            \n",
    "            heatmaps_result, offsets_result, displacement_fwd_result, displacement_bwd_result = sess.run(\n",
    "                model_outputs,\n",
    "                feed_dict={'image:0': input_image}\n",
    "            )\n",
    "\n",
    "            pose_scores, keypoint_scores, keypoint_coords = posenet.decode_multi.decode_multiple_poses(\n",
    "                heatmaps_result.squeeze(axis=0),\n",
    "                offsets_result.squeeze(axis=0),\n",
    "                displacement_fwd_result.squeeze(axis=0),\n",
    "                displacement_bwd_result.squeeze(axis=0),\n",
    "                output_stride=output_stride,\n",
    "                max_pose_detections=10,\n",
    "                min_pose_score=0.15)\n",
    "\n",
    "            keypoint_coords *= output_scale\n",
    "\n",
    "            # TODO this isn't particularly fast, use GL for drawing and display someday...\n",
    "            overlay_image = posenet.draw_skel_and_kp(\n",
    "                display_image, pose_scores, keypoint_scores, keypoint_coords,\n",
    "                min_pose_score=0.15, min_part_score=0.1)\n",
    "            \n",
    "            #overlay_image = cv2.resize(overlay_image, (1024, 960))\n",
    "            overlay_image = cv2.resize(overlay_image, (600, 900))\n",
    "            minimum_found = False\n",
    "\n",
    "            imageQ.append(overlay_image)\n",
    "            for pi in range(len(pose_scores)):\n",
    "                if pose_scores[pi] == 0.:\n",
    "                    break\n",
    "                #logging.warning('Pose #%d, score = %f' % (pi, pose_scores[pi]))\n",
    "                for ki, (s, c) in enumerate(zip(keypoint_scores[pi, :], keypoint_coords[pi, :, :])):\n",
    "                    if posenet.PART_NAMES[ki] == \"leftEye\":\n",
    "                        #print('Keypoint %s, score = %f, coord = %s' % (posenet.PART_NAMES[ki], s, c))\n",
    "                        #adding coordinate to running queue\n",
    "                        runningQ.append(c[0])\n",
    "                        #append more infomation to other queues here\n",
    "                        \n",
    "                        #if length equals 7, then will see if mid point is the min\n",
    "                        if len(runningQ) == 7:\n",
    "                            if findMin(runningQ) != 0:\n",
    "                                #print('FOUND MIN')\n",
    "                                minimum_found = True\n",
    "                                #print(findMin(runningQ))\n",
    "                            runningQ.popleft()\n",
    "                            #popleft to all other queues you create for more info here\n",
    "                    if posenet.PART_NAMES[ki] in body_points:\n",
    "                        body_points[posenet.PART_NAMES[ki]] = c\n",
    "                        body_points_score[posenet.PART_NAMES[ki]] = s\n",
    "                        \n",
    "                            \n",
    "                        \n",
    "            info_dict['Body Points'] = body_points\n",
    "            info_dict['Body Points Score'] = body_points_score\n",
    "            \n",
    "            #Calculate the average confidence score of the shoulder, elbow, and wrist\n",
    "            confidence_right = body_points_score['rightShoulder'] + body_points_score['rightElbow'] + body_points_score['rightWrist']\n",
    "            confidence_left = body_points_score['leftShoulder'] + body_points_score['leftElbow'] + body_points_score['leftWrist']\n",
    "            confidence_right /= 3\n",
    "            confidence_left /= 3\n",
    "            info_dict['Scores Right'] = confidence_right\n",
    "            info_dict['Scores Left'] = confidence_left\n",
    "            info_dict['Image'] = overlay_image\n",
    "            \n",
    "            if delay_count < delay:\n",
    "                infoQ.append(info_dict)\n",
    "                delay_count+=1\n",
    "            else:\n",
    "                oldQ = infoQ.popleft()\n",
    "                infoQ.append(info_dict)\n",
    "                \n",
    "            if print_min and minimum_found:\n",
    "                for i in np.arange(3):\n",
    "                    avg_r += infoQ[i]['']\n",
    "                #Calculate angle between shoulder and wrist using the elbow as the origin\n",
    "                angle_right = angle((oldQ['Body Points']['rightShoulder']-oldQ['Body Points']['rightElbow']),(oldQ['Body Points']['rightWrist']-oldQ['Body Points']['rightElbow']))\n",
    "                angle_left = angle((oldQ['Body Points']['leftShoulder']-oldQ['Body Points']['leftElbow']),(oldQ['Body Points']['leftWrist']-oldQ['Body Points']['leftElbow']))\n",
    "                print('Maximum Height Found')\n",
    "                print('Angle Right: %f degrees with confidence %f' %(angle_right,confidence_right))\n",
    "                print('Angle Left: %f degrees with confidence %f' %(angle_left,confidence_left))\n",
    "                print()\n",
    "                cv2.imwrite(r'C:\\Users\\micha\\Desktop\\ML\\113dbspring19\\posenet-python-master\\posenet-python-master\\output\\maximum_squat' + exercise + str(picture_count) + '.jpg',oldQ['Image'])\n",
    "\n",
    "                picture_count += 1\n",
    "            cv2.imshow('posenet', overlay_image)\n",
    "            frame_count += 1\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows();\n",
    "        print('Average FPS: ', frame_count / (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_r = 0\n",
    "for i in np.arange(4):\n",
    "    print(infoQ[i]['Scores Right'])\n",
    "    avg_r += infoQ[i]['Scores Right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
